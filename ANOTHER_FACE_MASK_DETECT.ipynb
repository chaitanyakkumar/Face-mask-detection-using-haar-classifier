{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"D:\\ml\\kaggle datasets\\dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['without_mask', 'with_mask']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i for i in range(len(categories))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = dict(zip(categories,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'without_mask': 0, 'with_mask': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 100\n",
    "data =[]\n",
    "target = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n",
      "Exception: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "    folder_path = os.path.join(data_path,category)\n",
    "    img_names = os.listdir(folder_path)\n",
    "    \n",
    "    for img_name in img_names:\n",
    "        image_path = os.path.join(folder_path,img_name)\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        try:\n",
    "            img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            resized_img = cv2.resize(img_gray,(img_size,img_size))\n",
    "            data.append(resized_img)\n",
    "            target.append(label_dict[category])\n",
    "        except Exception as e:\n",
    "            print(\"Exception:\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4428, 4428)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data),len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4428, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.reshape(data,(data.shape[0],img_size,img_size,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4428, 100, 100, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#1st layer\n",
    "model.add(Conv2D(filters = 6,kernel_size = (3,3),strides = (1,1),padding = 'valid',input_shape = (100,100,1))) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2),strides = (2,2)))\n",
    "\n",
    "#2nd layer\n",
    "model.add(Conv2D(filters = 16,kernel_size = (3,3),strides = (2,2),padding = 'valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2),strides = (2,2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(120,activation = 'relu'))\n",
    "model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 98, 98, 6)         60        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 98, 98, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 16)        880       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               276600    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 121       \n",
      "=================================================================\n",
      "Total params: 277,661\n",
      "Trainable params: 277,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['accuracy',keras.metrics.Precision(),keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits = 1,test_size = 0.1,random_state = 42)\n",
    "for train_index,test_index in split.split(data,target):\n",
    "    X_train,y_train = data[train_index],target[train_index]\n",
    "    X_test,y_test = data[test_index],target[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3985, 100, 100, 1), (443, 100, 100, 1), (3985, 1), (443, 1))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3188 samples, validate on 797 samples\n",
      "Epoch 1/25\n",
      "3188/3188 [==============================] - 15s 5ms/step - loss: 0.6086 - accuracy: 0.6719 - precision: 0.6175 - recall: 0.7389 - val_loss: 0.5035 - val_accuracy: 0.7465 - val_precision: 0.6841 - val_recall: 0.8038\n",
      "Epoch 2/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.4667 - accuracy: 0.7826 - precision: 0.7085 - recall: 0.8248 - val_loss: 0.3530 - val_accuracy: 0.8670 - val_precision: 0.7348 - val_recall: 0.8320\n",
      "Epoch 3/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.3625 - accuracy: 0.8394 - precision: 0.7571 - recall: 0.8426 - val_loss: 0.2892 - val_accuracy: 0.8971 - val_precision: 0.7737 - val_recall: 0.8487\n",
      "Epoch 4/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.3106 - accuracy: 0.8698 - precision: 0.7860 - recall: 0.8569 - val_loss: 0.2747 - val_accuracy: 0.9009 - val_precision: 0.7986 - val_recall: 0.8644\n",
      "Epoch 5/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.2768 - accuracy: 0.8852 - precision: 0.8076 - recall: 0.8698 - val_loss: 0.2502 - val_accuracy: 0.9059 - val_precision: 0.8170 - val_recall: 0.8740\n",
      "Epoch 6/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.2482 - accuracy: 0.8955 - precision: 0.8250 - recall: 0.8763 - val_loss: 0.2197 - val_accuracy: 0.9147 - val_precision: 0.8321 - val_recall: 0.8800\n",
      "Epoch 7/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.2077 - accuracy: 0.9097 - precision: 0.8378 - recall: 0.8843 - val_loss: 0.2108 - val_accuracy: 0.9285 - val_precision: 0.8435 - val_recall: 0.8873\n",
      "Epoch 8/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.1951 - accuracy: 0.9241 - precision: 0.8491 - recall: 0.8907 - val_loss: 0.2073 - val_accuracy: 0.9260 - val_precision: 0.8539 - val_recall: 0.8936\n",
      "Epoch 9/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.1779 - accuracy: 0.9250 - precision: 0.8581 - recall: 0.8957 - val_loss: 0.1789 - val_accuracy: 0.9322 - val_precision: 0.8624 - val_recall: 0.8985\n",
      "Epoch 10/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.1446 - accuracy: 0.9457 - precision: 0.8668 - recall: 0.9012 - val_loss: 0.2057 - val_accuracy: 0.9109 - val_precision: 0.8709 - val_recall: 0.9031\n",
      "Epoch 11/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.1374 - accuracy: 0.9495 - precision: 0.8748 - recall: 0.9048 - val_loss: 0.1661 - val_accuracy: 0.9460 - val_precision: 0.8784 - val_recall: 0.9071\n",
      "Epoch 12/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.1222 - accuracy: 0.9558 - precision: 0.8817 - recall: 0.9097 - val_loss: 0.1644 - val_accuracy: 0.9410 - val_precision: 0.8847 - val_recall: 0.9117\n",
      "Epoch 13/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.1119 - accuracy: 0.9583 - precision: 0.8877 - recall: 0.9136 - val_loss: 0.1673 - val_accuracy: 0.9486 - val_precision: 0.8905 - val_recall: 0.9155\n",
      "Epoch 14/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.1101 - accuracy: 0.9580 - precision: 0.8929 - recall: 0.9172 - val_loss: 0.2042 - val_accuracy: 0.9222 - val_precision: 0.8954 - val_recall: 0.9184\n",
      "Epoch 15/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.0976 - accuracy: 0.9633 - precision: 0.8977 - recall: 0.9195 - val_loss: 0.1732 - val_accuracy: 0.9473 - val_precision: 0.8999 - val_recall: 0.9211\n",
      "Epoch 16/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.0821 - accuracy: 0.9693 - precision: 0.9019 - recall: 0.9229 - val_loss: 0.1721 - val_accuracy: 0.9448 - val_precision: 0.9038 - val_recall: 0.9245\n",
      "Epoch 17/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.0763 - accuracy: 0.9715 - precision: 0.9056 - recall: 0.9262 - val_loss: 0.1865 - val_accuracy: 0.9322 - val_precision: 0.9075 - val_recall: 0.9273\n",
      "Epoch 18/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.0817 - accuracy: 0.9724 - precision: 0.9094 - recall: 0.9283 - val_loss: 0.1707 - val_accuracy: 0.9460 - val_precision: 0.9110 - val_recall: 0.9294\n",
      "Epoch 19/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.0682 - accuracy: 0.9777 - precision: 0.9127 - recall: 0.9306 - val_loss: 0.1695 - val_accuracy: 0.9448 - val_precision: 0.9144 - val_recall: 0.9318\n",
      "Epoch 20/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.0718 - accuracy: 0.9743 - precision: 0.9158 - recall: 0.9327 - val_loss: 0.1605 - val_accuracy: 0.9511 - val_precision: 0.9172 - val_recall: 0.9338\n",
      "Epoch 21/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.0578 - accuracy: 0.9827 - precision: 0.9186 - recall: 0.9350 - val_loss: 0.1614 - val_accuracy: 0.9498 - val_precision: 0.9201 - val_recall: 0.9360\n",
      "Epoch 22/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.0589 - accuracy: 0.9802 - precision: 0.9214 - recall: 0.9369 - val_loss: 0.1853 - val_accuracy: 0.9448 - val_precision: 0.9227 - val_recall: 0.9378\n",
      "Epoch 23/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.0503 - accuracy: 0.9840 - precision: 0.9239 - recall: 0.9386 - val_loss: 0.1959 - val_accuracy: 0.9473 - val_precision: 0.9252 - val_recall: 0.9395\n",
      "Epoch 24/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.0537 - accuracy: 0.9821 - precision: 0.9263 - recall: 0.9403 - val_loss: 0.2312 - val_accuracy: 0.9147 - val_precision: 0.9274 - val_recall: 0.9408\n",
      "Epoch 25/25\n",
      "3188/3188 [==============================] - 13s 4ms/step - loss: 0.0476 - accuracy: 0.9849 - precision: 0.9285 - recall: 0.9413 - val_loss: 0.1918 - val_accuracy: 0.9511 - val_precision: 0.9295 - val_recall: 0.9421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x25ca2481f88>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 25,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17204957859039846,\n",
       " 0.9458239078521729,\n",
       " 0.929636538028717,\n",
       " 0.9422425031661987]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =(y_pred > 0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[178,  16],\n",
       "       [  8, 241]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25ca3698d08>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(cm, cmap = plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_clsfr = cv2.CascadeClassifier(r'D:\\ml\\pre_trained_models\\Face-Mask-Detector-master\\haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {0:'WITHOUT_MASK',1:'MASK'}\n",
    "color_dict = {0:(0,0,255),1:(0,255,0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret,img = video_capture.read()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_clsfr.detectMultiScale(gray,1.3,5)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        face_img = gray[y:y+h,x:x+w]\n",
    "        resize_img = cv2.resize(face_img,(100,100))\n",
    "        normalized_img = resize_img/255.0\n",
    "        reshaped_img = np.reshape(normalized_img,(1,100,100,1))\n",
    "        result = model.predict(reshaped_img)\n",
    "                \n",
    "        label = np.argmax(result,axis = 1)[0]\n",
    "\n",
    "        \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        cv2.rectangle(img,(x,y-40),(x+w,y),color_dict[label],-1)\n",
    "        cv2.putText(img,label_dict[label],(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "    \n",
    "    cv2.imshow('LIVE',img)\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if (key == 27):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "video_capture.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
